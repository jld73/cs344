{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage:\n",
    "The program auto_mnist.py should be runnable with only the basic keras, numpy, pandas, matplotlib, and PIL.\n",
    "The program auto_mario.py will require my custom dataset, which I'm not sure how to get to you. \n",
    "the programs should be run with two arguments, the first is the number of features to track; I reccomend 16 for mnist, and 32-48 for mario, the second is the number of epochs to train for.\n",
    "\n",
    "Vision: This project is designed to be a visualization of how a neural network learns. By modifying the weights of a network manually and observing how the resulting image changes, we can explicitly see what each weight encodes. This allows us to understand better how a neural network \"learns\" the information. For example, in the video I link below, the node with the most significant effect on the image is the shading. Thus, we can learn that the image is  I could also tell us more about the problem for which it is trained. For example, if we trained it on the mnist dataset, and find that the most significant weight is X, it would tell us that that specific element of numbers is an important distinction. This idea was also extended to the less structured dataset of Super Mario World screenshots. By using an autoencoder to encode the information down to a small enough set of features, the hope is that the features it encodes will show what is most important in the images. These encodings could then be passed off to a network designed to play the game, where the network would take the encodings of the current frame as input, and give as output the buttons that should be pressed on that frame. By using an encoding in this way, it would allow the game-playing network to view the screen in a way analogous to how a human would, unlike other current implementations like SethBling's marI/O, which just look at values directly from the SNES's RAM.\n",
    "\n",
    "Background: This idea for the autoencoder portion was inspired by the video by Carykh here: https://www.youtube.com/watch?v=NTlXEJjfsQU, in fact, a lot of my interest in AI came from Carykh. One of his earlier videos introduced me to the concept of autoencoders. These networks essentially use the same data point for both input and output, so the network simply tries to reconstruct the image. However, the network is built in an hourglass shape, with the middle layer being much smaller than the input or output. This way, the information must be \"squeezed\" down and compressed, meaning that the network must learn what is important about the images in the given dataset in order to be able to reconstruct them with only a small portion of the original information. https://blog.keras.io/building-autoencoders-in-keras.html \n",
    "The Mario section of this project was inspired by SethBling's MarI/O network, which was designed to play Mario using a neural network with the NEAT architecture https://www.youtube.com/watch?v=qv6UVOQ0F44. The NEAT algorithm is a variation of a genetic algorithm. It begins each network as a single layer network with no hidden layers or connections. At the start of each generation, every network in the group will be mutated from the following list of possible mutations. It can add a new connection + weight between two unconnected nodes, it can add a new node to an existing connection, and it can adjust the weight of an existing connection. By repeating this for many generations, the topology of the networks can evolve to have large, effective networks that are at less risk of overfitting since the networks only grow when the growth helps them improve.\n",
    "I used Keras for the implementation, and used Tkinter to build a GUI to facilitate changing the inputs, and show the output in real time.\n",
    "I used BizHawk emulator to run Super Mario World in order to get screenshots and to run the NEAT algorithm.\n",
    "\n",
    "Implementation: I began the process by implementing an autoencoder for the MNIST dataset as is done here: https://medium.com/datadriveninvestor/simple-autoencoders-using-keras-6e67677f5679. After getting this autoencoder working reliably, I figured out how to break apart the autoencoder into 3 parts, the encoder, the decoder, and the encoding (as well as the autoencoder, which is just the result of the encoder fed directly into the decoder). By breaking it up this way, I was able to capture the output of the encoder and display it to a tkinter display panel. This would let us see the encoding for each image that it encoded as numerical values. I then added a panel to the UI that would display the current encoding as a series of sliders that the user can modify to dynamically change the weights around. I then created an image panel that would display the result of feeding the current set of values into the decoder. Finally I added another image panel, and a button which, when pressed, would grab a random image from the test data set, plug it into the encoder, and set all the weights equal to that images encoding, as well as displaying it on screen. After getting everything working with the MNIST dataset, I booted up BizHawk and recorded a bunch of screenshots from Super Mario World. I then created a data parser that would load the images into a copy of the program, crop them into a good format, convert them into numpy arrays, and train the network on those images instead.\n",
    "https://keras.io/examples/mnist_denoising_autoencoder/\n",
    "\n",
    "Results: The MNIST dataset had some very interesting results. I noticed that each node in the encoding would typically encode one or two features. For example, one node might encode a line vs \"O\" shape for a certain part of the image. I could also set all of the weights to 0 and modify just one at a time to see what each shape each node made in isolation, often each would make a broken figure. Also, occasionally one node would encode a full digit, especially with long training periods and many features. Another thing that I found was that there were generally one or two dead Relu units, which can no longer used by the encoder. However, these values can still be modified, and will show the vestigial function of that node before it died in the training process. For the Mario dataset, the results were less impressive, but still interesting. I noticed that each node seemed to learn a couple of different screen shots, then the final image would just be a composite of several, with the most important features being the most pronounced. Another interesting thing to note was that the Mario network had many dead Relus, probably close to half. I believe the reason for this was that there were a lot of features that were really small, like enemies and blocks, that would get drowned out by the larger stuff like terrain and the background. Because the background took up so many pixels, and the network didn't have a sense of what was important in the image, it tried to match the background above all, as it would contribute the most to its score. Thus, any nodes that tried to encode less significant information would simply be drowned out by the ones encoding higher order information, eventually dying out. I think this issue could be addressed by using a CNN in the encoder, to force it to focus on lower level details. In fact, by using a 16 by 16 convolution, it might be possible for the network to develop a \"spritemap\" like the game does. Unfortunately, I was not able to get the CNN working in time.\n",
    "Also unfortunately, the Super Mario World NEAT connection didn't work out. While I was able to get the NEAT implementation running, due to BizHawks lua sandbox it was not able to interact with the python programs. \n",
    "\n",
    "Implications: Social implications could be that it would help people who are learning about neural networks to understand what's going on behind the scenes of the networks they are writing. It could also inform some efforts into examining nature of learning in non-human contexts for similar reasons. Ethically, there are some concerns with the ability to create arbitrary data. For example, the ability to generate faces could be used to create fake identification documents. Of course, people can already do this with image editing tools, but technology like this could potentially make the process easier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=NTlXEJjfsQU\n",
    "https://blog.keras.io/building-autoencoders-in-keras.html\n",
    "https://www.youtube.com/watch?v=qv6UVOQ0F44\n",
    "https://medium.com/datadriveninvestor/simple-autoencoders-using-keras-6e67677f5679\n",
    "https://keras.io/examples/mnist_denoising_autoencoder/\n",
    "http://scipy-lectures.org/advanced/image_processing/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
