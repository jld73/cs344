{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vision: This project is desinged to be a visualization of how a nueral network learns. By modifying the weights of a network manually and observing how the resulting image changes, we can explicitly see what each wieght encodes. This allows us to understand better how a nueral network \"learns\" the information. For example, in the video I link below, the node with the most significant effect on the image is the shading. Thus, we can learn that the image is  I could also tell us more about the problem for which it is trained. For example, if we trained it on the mnist dataset, and find that the most significant wieght is X, it would tell us that that specific element of numbers is an important distinction.\n",
    "\n",
    "Background: This idea was inspired by the video by Carykh here: https://www.youtube.com/watch?v=NTlXEJjfsQU, in fact, a lot of my interest in AI came from Carykh. One of his earlier videos introduced me to the concept of autoencoders. These networks essentially use the same data point for both input and output, so the network simply tries to reconstruct the image. However, the network is built in an hourglass shape, with the middle layer being much smaller than the input or output. This way, the information must be \"squeezed\" down and compressed, meaning that the network must learn what is important about the images in the given dataset in order to be able to reconstruct them with only a small portion of the original information.\n",
    "I plan to use Keras for the implementation, perhaps using Tkinter to build a small GUI to facilitate changing the inputs, and showing the output.\n",
    "\n",
    "Implementation: I plan on building the autoencoder model, then removing the encoder layers and replacing them with a manual input directly to the decoder. From there I should be able to generate any image it could possibly generate by manually adjusting the inputs. \n",
    "\n",
    "Results: none yet\n",
    "Implications: Social implications could be that it would help people who are learning about neural networks to understand what's going on behind the scenes of the networks they are writing. It could also inform some efforts into examining nature of learning in non-human contexts for similar reasons. Ethically, there are some concerns with the ability to create arbitrary data. For example, the ability to generate faces could be used to create fake identification documents. Of course, people can already do this with image editing tools, but technology like this could potentially make the process easier. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
